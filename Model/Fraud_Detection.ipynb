{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad64a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import textstat\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class JobFraudModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.vectorizer = None\n",
    "        self.best_params = None\n",
    "\n",
    "    def extract_features(self, df):\n",
    "        features = pd.DataFrame()\n",
    "        features['title_length'] = df['title'].str.len().fillna(0)\n",
    "        features['description_length'] = df['description'].str.len().fillna(0)\n",
    "        features['word_count'] = df['description'].str.split().str.len().fillna(0)\n",
    "        features['avg_word_length'] = df['description'].apply(\n",
    "            lambda x: np.mean([len(w) for w in str(x).split()]) if pd.notna(x) and len(str(x).split()) > 0 else 0\n",
    "        )\n",
    "        features['readability'] = df['description'].apply(\n",
    "            lambda x: textstat.flesch_reading_ease(str(x)) if pd.notna(x) else 0\n",
    "        )\n",
    "        features['caps_ratio'] = df['description'].apply(\n",
    "            lambda x: sum(c.isupper() for c in str(x)) / max(len(str(x)), 1)\n",
    "        )\n",
    "        features['digit_ratio'] = df['description'].apply(\n",
    "            lambda x: sum(c.isdigit() for c in str(x)) / max(len(str(x)), 1)\n",
    "        )\n",
    "        features['punct_ratio'] = df['description'].apply(\n",
    "            lambda x: sum(1 for c in str(x) if c in '.,!?') / max(len(str(x)), 1)\n",
    "        )\n",
    "        features['stopword_ratio'] = df['description'].apply(\n",
    "            lambda x: len([w for w in str(x).lower().split() if w in ENGLISH_STOP_WORDS]) / max(len(str(x).split()), 1)\n",
    "        )\n",
    "        # Pattern flags\n",
    "        patterns = {\n",
    "            'urgent_kw': r'urgent|asap|immediate|quick|fast|now|hurry|rush',\n",
    "            'money_kw': r'\\$|money|payment|earn|income|profit|cash|dollar|pay|salary|wage',\n",
    "            'contact_kw': r'email|phone|whatsapp|telegram|contact|call|text|message',\n",
    "            'guarantee_kw': r'guarantee|promised|assured|certain|sure|definitely',\n",
    "            'easy_kw': r'easy|simple|no experience|entry level|beginner|basic',\n",
    "            'remote_kw': r'remote|work from home|anywhere|global|worldwide|online'\n",
    "        }\n",
    "        for key, pat in patterns.items():\n",
    "            features[key] = df['description'].str.contains(pat, case=False, na=False)\n",
    "        features['title_urgent'] = df['title'].str.contains(patterns['urgent_kw'], case=False, na=False)\n",
    "        features['title_money'] = df['title'].str.contains(patterns['money_kw'], case=False, na=False)\n",
    "        features['title_easy'] = df['title'].str.contains(patterns['easy_kw'], case=False, na=False)\n",
    "        features['company_length'] = df.get('company', pd.Series([''] * len(df))).apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "        features['has_company'] = df.get('company', pd.Series([''] * len(df))).apply(lambda x: int(pd.notna(x) and str(x).strip() != ''))\n",
    "        features['remote_work'] = df.get('location', pd.Series([''] * len(df))).str.contains(patterns['remote_kw'], case=False, na=False).fillna(False).astype(int)\n",
    "        return features\n",
    "\n",
    "    def preprocess_text(self, df):\n",
    "        text = (df['title'].fillna('') + ' ' + df['description'].fillna('')).str.lower()\n",
    "        text = text.str.replace(r'http\\S+', ' ', regex=True)\n",
    "        text = text.str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "        text = text.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "        return text\n",
    "\n",
    "    def train_model(self, df, target_col='fraudulent', model_type='xgboost', balance_method='smotetomek'):\n",
    "        structural = self.extract_features(df)\n",
    "        text_data = self.preprocess_text(df)\n",
    "        self.vectorizer = TfidfVectorizer(max_features=3000, stop_words='english', ngram_range=(1, 2))\n",
    "        text_features = self.vectorizer.fit_transform(text_data).toarray()\n",
    "        text_df = pd.DataFrame(text_features)\n",
    "\n",
    "        # Combine features\n",
    "        X = pd.concat([structural.reset_index(drop=True), text_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        #  Save feature names to JSON here\n",
    "        import json\n",
    "        with open(\"feature_names.json\", \"w\") as f:\n",
    "            json.dump(list(X.columns), f)\n",
    "\n",
    "        # Ensure column names are string\n",
    "        X.columns = X.columns.map(str)\n",
    "\n",
    "        # Fill NaNs\n",
    "        X = X.fillna(0)\n",
    "\n",
    "        # Target\n",
    "        y = df[target_col].astype(int)\n",
    "\n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
    "\n",
    "        # Apply balancing\n",
    "        if balance_method == 'smotetomek':\n",
    "            sampler = SMOTETomek(random_state=42)\n",
    "        elif balance_method == 'smote':\n",
    "            sampler = SMOTE(random_state=42)\n",
    "        else:\n",
    "            sampler = None\n",
    "\n",
    "        if sampler:\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train model\n",
    "        if model_type == 'xgboost':\n",
    "            model = XGBClassifier(random_state=42, eval_metric='logloss', n_jobs=-1)\n",
    "            param_grid = {'max_depth': [4, 6], 'learning_rate': [0.1], 'n_estimators': [100]}\n",
    "        else:\n",
    "            model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "            param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20, None]}\n",
    "            \n",
    "        grid = GridSearchCV(model, param_grid, scoring='f1', cv=StratifiedKFold(3, shuffle=True, random_state=42), n_jobs=1, verbose=1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        self.model = grid.best_estimator_\n",
    "        self.best_params = grid.best_params_\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(\"ðŸ“Š Test Set Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "    def save_model(self, model_path='model.pkl', vectorizer_path='vectorizer.pkl'):\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        with open(vectorizer_path, 'wb') as f:\n",
    "            pickle.dump(self.vectorizer, f)\n",
    "\n",
    "    def load_model(self, model_path='model.pkl', vectorizer_path='vectorizer.pkl'):\n",
    "        with open(model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        with open(vectorizer_path, 'rb') as f:\n",
    "            self.vectorizer = pickle.load(f)\n",
    "\n",
    "    def predict(self, df):\n",
    "        structural = self.extract_features(df)\n",
    "        text_data = self.preprocess_text(df)\n",
    "        text_features = self.vectorizer.transform(text_data).toarray()\n",
    "        text_df = pd.DataFrame(text_features)\n",
    "        X = pd.concat([structural.reset_index(drop=True), text_df.reset_index(drop=True)], axis=1)\n",
    "        X = X.fillna(0)\n",
    "        preds = self.model.predict(X)\n",
    "        probs = self.model.predict_proba(X)[:, 1]\n",
    "        return preds, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fc937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "ðŸ“Š Test Set Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2722\n",
      "           1       0.80      0.58      0.67       139\n",
      "\n",
      "    accuracy                           0.97      2861\n",
      "   macro avg       0.89      0.78      0.83      2861\n",
      "weighted avg       0.97      0.97      0.97      2861\n",
      "\n",
      "âœ… Predictions saved to test_predictions_with_probs.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # TRAINING\n",
    "    df = pd.read_csv(\"Training Data.csv\")\n",
    "    trainer = JobFraudModelTrainer()\n",
    "    trainer.train_model(df, target_col='fraudulent', model_type='xgboost', balance_method='smotetomek')\n",
    "    trainer.save_model(\"fraud_detector.pkl\", \"vectorizer.pkl\")\n",
    "\n",
    "    # PREDICTION\n",
    "    test_df = pd.read_csv(\"Test Data.csv\")\n",
    "    trainer.load_model(\"fraud_detector.pkl\", \"vectorizer.pkl\")\n",
    "    preds, probs = trainer.predict(test_df)\n",
    "    test_df['predicted_label'] = preds\n",
    "    test_df['fraud_probability'] = probs\n",
    "    test_df.to_csv(\"test_predictions_with_probs.csv\", index=False)\n",
    "    print(\"âœ… Predictions saved to test_predictions_with_probs.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
